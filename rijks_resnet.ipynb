{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import paint_auth as pa\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import resnet\n",
    "import glob\n",
    "from lxml import etree as ET\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shuffle(X, y):\n",
    "    indices = np.arange(len(X))\n",
    "    np.random.shuffle(indices)\n",
    "    return X[indices], y[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all xml and convert to pd dataframe\n",
    "#only extract painters\n",
    "path = '/Users/Mason/Desktop/adv_big_data/data/xml2'\n",
    "file_names = glob.glob(path+'/**')\n",
    "\n",
    "#initialize dict and parser\n",
    "info = {}\n",
    "parser = ET.XMLParser(recover=True)\n",
    "for i in range(len(file_names)):\n",
    "    im_name = file_names[i].split('/')[-1]\n",
    "    tree = ET.parse(file_names[i], parser)\n",
    "    title, artist, medium, period = pa.extract_info(tree.getroot())\n",
    "    if medium == 'schilderij' or medium == 'tekening': #painting or drawing in Dutch...\n",
    "        if artist is not None:\n",
    "            artist = artist.split(': ')[-1]\n",
    "        im_name = im_name.split('.xml')[0]\n",
    "        info[i] = (im_name, title, artist, medium, period)\n",
    "\n",
    "info = pd.DataFrame.from_dict(info, 'index').rename(index=str, columns={0:'file_name', 1:'title', 2:'artist', 3:'medium', 4:'period'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#counting and sorting artists' number of paintings\n",
    "counts = Counter(info['artist'].tolist())\n",
    "counts = pd.DataFrame.from_dict(counts, orient='index').sort_values(by=0,ascending=False)\n",
    "#getting subset of artists with decent number of paintings\n",
    "my_artists = counts.index[1:6].tolist()\n",
    "my_artists = info[info['artist'].isin(my_artists)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imported images: 100\n",
      "imported images: 200\n",
      "imported images: 300\n",
      "imported images: 400\n",
      "imported images: 500\n",
      "imported images: 600\n",
      "imported images: 700\n",
      "imported images: 800\n",
      "imported images: 900\n",
      "imported images: 1000\n",
      "imported images: 1100\n",
      "imported images: 1200\n",
      "imported images: 1300\n",
      "imported images: 1400\n"
     ]
    }
   ],
   "source": [
    "image_path = '/Users/Mason/Desktop/adv_big_data/data/jpg2'\n",
    "paintings, mult, one_hot = pa.import_dataset(image_path, my_artists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(paintings, one_hot, test_size=0.2, stratify=one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize training\n",
    "import cv2\n",
    "t = cv2.normalize(X_train[0].astype('float32'), None, 0.0, 1.0, cv2.NORM_MINMAX)\n",
    "X_train = np.array([cv2.normalize(image.astype('float32'), None, 0.0, 1.0, cv2.NORM_MINMAX) for image in X_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 5)\n"
     ]
    }
   ],
   "source": [
    "#initializing Resnet\n",
    "#hyperparams\n",
    "alpha = 1e-2\n",
    "BATCH_SIZE = 200\n",
    "epochs = 25\n",
    "n_classes = len(y_train[0])\n",
    "shape = (256,256,3)\n",
    "optimizer = tf.train.AdamOptimizer(alpha)\n",
    "sess = tf.Session()\n",
    "model = resnet.Resnet(shape, n_classes, optimizer, sess)\n",
    "model.build_model()\n",
    "model.build_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.19132851, 0.18727882, 0.19008645, 0.21685773, 0.21444847]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test run\n",
    "model.predict([X_train[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch: 0\n",
      "beginning training for iteration: 0\n",
      "beginning training for iteration: 1\n",
      "beginning training for iteration: 2\n",
      "beginning training for iteration: 3\n",
      "beginning training for iteration: 4\n",
      "beginning training for iteration: 5\n",
      "beginning training for iteration: 6\n",
      "beginning training for iteration: 7\n",
      "beginning training for iteration: 8\n",
      "beginning training for iteration: 9\n",
      "beginning training for iteration: 10\n"
     ]
    }
   ],
   "source": [
    "train_acc = []\n",
    "val_acc = []\n",
    "#training\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for ep in range(epochs):\n",
    "    count = 0\n",
    "    print 'starting epoch: %d' % ep\n",
    "    X_train, y_train = shuffle(X_train, y_train)\n",
    "    #train, val split\n",
    "    \n",
    "    X_t, X_val, y_t, y_val = train_test_split(X_train, y_train, stratify=y_train, test_size=0.2)\n",
    "    for offset in range(0, len(y_train), BATCH_SIZE):\n",
    "        print 'beginning training for iteration: %d' % count\n",
    "        batch_X = X_t[offset: offset + BATCH_SIZE]\n",
    "        batch_y = y_t[offset: offset + BATCH_SIZE]\n",
    "\n",
    "        model.train(batch_X, batch_y)\n",
    "        count += 1\n",
    "        \n",
    "    train_p = model.predict(X_t)\n",
    "    val_p = model.predict(X_val)\n",
    "    \n",
    "    #retrieving labels\n",
    "    train_p_labels = np.argmax(train_p, 1)\n",
    "    val_p_labels = np.argmax(val_p, 1)\n",
    "    y_t_labels = np.argmax(y_t, 1)\n",
    "    y_val_labels = np.argmax(y_val, 1)\n",
    "    \n",
    "    t_acc = np.mean((y_t_labels-train_p_labels)==0)\n",
    "    v_acc = np.mean((y_val_labels-val_p_labels)==0)\n",
    "    \n",
    "    print 'train acc.: %f' % t_acc\n",
    "    print 'validation acc.: %f' % v_acc\n",
    "    \n",
    "    train_acc.append(t_acc)\n",
    "    val_acc.append(v_acc)\n",
    "    \n",
    "    #plotting\n",
    "    t = range(len(train_acc))\n",
    "    plt.plot(t, train_acc, 'b')\n",
    "    plt.plot(t, val_acc, 'g')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

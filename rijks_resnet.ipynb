{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import paint_auth as pa\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import resnet\n",
    "import glob\n",
    "from lxml import etree as ET\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all xml and convert to pd dataframe\n",
    "#only extract painters\n",
    "path = '/Users/Mason/Desktop/adv_big_data/data/xml2'\n",
    "file_names = glob.glob(path+'/**')\n",
    "\n",
    "#initialize dict and parser\n",
    "info = {}\n",
    "parser = ET.XMLParser(recover=True)\n",
    "for i in range(len(file_names)):\n",
    "    im_name = file_names[i].split('/')[-1]\n",
    "    tree = ET.parse(file_names[i], parser)\n",
    "    title, artist, medium, period = pa.extract_info(tree.getroot())\n",
    "    if medium == 'schilderij' or medium == 'tekening': #painting or drawing in Dutch...\n",
    "        if artist is not None:\n",
    "            artist = artist.split(': ')[-1]\n",
    "        im_name = im_name.split('.xml')[0]\n",
    "        info[i] = (im_name, title, artist, medium, period)\n",
    "\n",
    "info = pd.DataFrame.from_dict(info, 'index').rename(index=str, columns={0:'file_name', 1:'title', 2:'artist', 3:'medium', 4:'period'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#counting and sorting artists' number of paintings\n",
    "counts = Counter(info['artist'].tolist())\n",
    "counts = pd.DataFrame.from_dict(counts, orient='index').sort_values(by=0,ascending=False)\n",
    "#getting subset of artists with decent number of paintings\n",
    "my_artists = counts.index[1:6].tolist()\n",
    "my_artists = info[info['artist'].isin(my_artists)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imported images: 100\n",
      "imported images: 200\n",
      "imported images: 300\n",
      "imported images: 400\n",
      "imported images: 500\n",
      "imported images: 600\n",
      "imported images: 700\n",
      "imported images: 800\n",
      "imported images: 900\n",
      "imported images: 1000\n",
      "imported images: 1100\n",
      "imported images: 1200\n",
      "imported images: 1300\n",
      "imported images: 1400\n"
     ]
    }
   ],
   "source": [
    "image_path = '/Users/Mason/Desktop/adv_big_data/data/jpg2'\n",
    "paintings, mult, one_hot = pa.import_dataset(image_path, my_artists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(paintings, one_hot, test_size=0.2, stratify=one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize training\n",
    "import cv2\n",
    "t = cv2.normalize(X_train[0].astype('float32'), None, 0.0, 1.0, cv2.NORM_MINMAX)\n",
    "X_train = np.array([cv2.normalize(image.astype('float32'), None, 0.0, 1.0, cv2.NORM_MINMAX) for image in X_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2088, 256, 256, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 5)\n"
     ]
    }
   ],
   "source": [
    "#initializing Resnet\n",
    "#hyperparams\n",
    "alpha = 1e-2\n",
    "BATCH_SIZE = 100\n",
    "n_classes = len(y_train[0])\n",
    "shape = (256,256,3)\n",
    "optimizer = tf.train.AdamOptimizer(alpha)\n",
    "sess = tf.Session()\n",
    "model = resnet.Resnet(shape, n_classes, optimizer, sess)\n",
    "model.build_model()\n",
    "model.build_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test run\n",
    "sess.run(tf.global_variables_initializer())\n",
    "model.predict([X_train[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beginning training for iteration: 0\n",
      "train acc.: 0.150000\n",
      "beginning training for iteration: 1\n",
      "train acc.: 0.170000\n",
      "beginning training for iteration: 2\n",
      "train acc.: 0.100000\n",
      "beginning training for iteration: 3\n",
      "train acc.: 0.220000\n",
      "beginning training for iteration: 4\n",
      "train acc.: 0.240000\n",
      "beginning training for iteration: 5\n",
      "train acc.: 0.340000\n",
      "beginning training for iteration: 6\n"
     ]
    }
   ],
   "source": [
    "train_acc = []\n",
    "BATCH_SIZE = 100\n",
    "#training\n",
    "count = 0\n",
    "for offset in range(0, len(y_train), BATCH_SIZE):\n",
    "    print 'beginning training for iteration: %d' % count\n",
    "    batch_X = X_train[offset: offset + BATCH_SIZE]\n",
    "    batch_y = y_train[offset: offset + BATCH_SIZE]\n",
    "    \n",
    "    model.train(batch_X, batch_y)\n",
    "    y_hat = model.predict(batch_X)\n",
    "    #retrieving labels\n",
    "    y_hat_labels = np.argmax(y_hat)\n",
    "    y_labels = np.argmax(batch_y, 1)\n",
    "    \n",
    "    acc = np.mean((y_labels-y_hat_labels)==0)\n",
    "    print 'train acc.: %f' % acc\n",
    "    train_acc.append(acc)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'div_3845:0' shape=(256, 256, 3) dtype=float32>"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
